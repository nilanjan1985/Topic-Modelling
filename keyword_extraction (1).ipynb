{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list = ['admiral','agri']\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78388898",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb8dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customtokenizer(text):\n",
    "    text_list =  text.split()\n",
    "    for punc in set(string.punctuation):\n",
    "        if punc in text_list:\n",
    "            text_list.remove(punc)\n",
    "        text_list = [i.strip(punc) for i in text_list] \n",
    "    return text_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b03e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898bdd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer = CountVectorizer(ngram_range=(1,len(entity_list)), stop_words=\"english\",tokenizer=customtokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50562b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {}\n",
    "new_df = pd.DatFrame([],columns=['entity','keyword'])\n",
    "for element in entity_list:\n",
    "    element = element.split()\n",
    "    if len(element) > 2:\n",
    "        n_minus_one_words = element[:-1]\n",
    "    elif len(element) <= 2:\n",
    "        n_minus_one_words = element\n",
    "        remove_words = ['LLC','Corporation']\n",
    "        n_minus_one_words = [elements for elements in n_minus_one_words if elements not in remove_words]\n",
    "        print(element)\n",
    "        print(n_minus_one_words)\n",
    "        print(' '.join(n_minus_one_words))\n",
    "        test = ' '.join(n_minus_one_words)\n",
    "        first_word = n_minus_one_words[0].lower()\n",
    "        doc = test\n",
    "        extracted_kw = kw_model.extract_keywords(doc,keyphrase_ngram_range=(1,len(n_minus_one_words)),vectorizer=vectorizer)\n",
    "        extracted_kw = [kw for kw in extracted_kw if kw[0].startswith(first_word)]\n",
    "        d2[doc] = extracted_kw\n",
    "        print(\"Extracted keywords:\", extracted_kw)\n",
    "        print(\"\\n\")\n",
    "        for k,_ in extracted_kw:\n",
    "            new_df_1.loc[len(new_df_1)] = [' '.join(element),k]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [new_df,new_df_1]\n",
    "keyword_extracted = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([(key, value) for _, list_of_kw in d1.items() for key,value in list_of_kw], columns = ['keyword','probability']\n",
    "df.to_csv('keywords_extracted_Cinven_1.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f10e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"keyword_extracted_Cinven (1).csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ebd83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://gis.ey.net/api/search/search-entities'\n",
    "\n",
    "no_of_hits_as_gup=[]\n",
    "\n",
    "for keyword in df['keyword'].to_list():\n",
    "    payload = {\"SearchExternal\": False,\"StandardSearchParameters\":{\"SearchTerm\": keyword,\"UseBestFields\":True,\"IsFuzzy\":False,\"OnlyActive\":True,\"IncludeDebug\":False}}\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        no_of_hits_as_gup.append(response.json()['TotalRecords']\n",
    "    else:\n",
    "        print(response.text)\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf8e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['No_of_hits_as GUP'] = no_of_hits_as_gup\n",
    "df_keywords_less__than_25  = df[df[\"No_of_hits_as_GUP\"] < 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c91ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_less_than_25['No_of_words_in_keyword'] = df_keywords_less_than_25.apply(lambda x : len(x['keyword'].split()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0cce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_cinven = df_keywords_less_than_25.groupby('entity',sort=False).apply(lambda x : x.loc[(x['No_of_hits_as_GUP'] == X['No_of_hits_as_GUP'].max()) & (x['No_of_words_in_keyword'] == x['No_of_words_in_keyword'].min()),['keyword','No_of_hits as_gup']].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e1631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cinven_25 = final_resut_cinven.to_csv('keyword_25.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
